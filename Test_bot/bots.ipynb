{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from g_python.gextension import Extension\n",
    "from g_python.hmessage import Direction, HMessage\n",
    "from g_python.hpacket import HPacket\n",
    "from g_python import hparsers\n",
    "from g_python import htools\n",
    "import sys\n",
    "from g_python.gextension import Extension\n",
    "from g_python.hdirection import Direction\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension_info = {\n",
    "    \"title\": \"Extension stuff\",\n",
    "    \"description\": \"g_python test\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"author\": \"sirjonasxx\"\n",
    "}\n",
    "sys.argv = ['-p', '9092']\n",
    "ext = Extension(extension_info, sys.argv)\n",
    "ext.start()\n",
    "\n",
    "# Carregar o modelo e o tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "# Função para verificar se uma string está codificada em UTF-8\n",
    "def is_utf8(data):\n",
    "    try:\n",
    "        data.encode('utf-8')\n",
    "        return True\n",
    "    except UnicodeError:\n",
    "        return False\n",
    "\n",
    "# Variável para armazenar mensagens já respondidas\n",
    "already_responded = set()\n",
    "\n",
    "# Função de interceptação e filtragem de mensagens\n",
    "def all_packets(message):\n",
    "    packet = message.packet\n",
    "    packet_str = packet.g_string(ext)\n",
    "    \n",
    "    # Extrair a frase da mensagem removendo números e arrays e caracteres extras\n",
    "    cleaned_message = re.sub(r'[\\[\\]\\d+Æ!)]', '', packet_str).strip()\n",
    "    \n",
    "    # Verifica se a mensagem contém a palavra \"Rasci\" (case-insensitive)\n",
    "    if re.search(r'kepler', cleaned_message, re.IGNORECASE):\n",
    "        # Verifica se a mensagem está codificada em UTF-8\n",
    "        if is_utf8(cleaned_message):\n",
    "            # Verifica se a mensagem já foi respondida\n",
    "            if cleaned_message not in already_responded:\n",
    "                # Armazena a mensagem capturada\n",
    "                print(f\"Mensagem capturada: {cleaned_message}\")\n",
    "                \n",
    "                # Gerar resposta usando o modelo de linguagem\n",
    "                inputs = tokenizer.encode(cleaned_message + tokenizer.eos_token, return_tensors=\"pt\")\n",
    "                outputs = model.generate(inputs, max_length=100, num_return_sequences=1)\n",
    "                response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                \n",
    "                # Enviar a resposta para o servidor\n",
    "                ext.send_to_server(HPacket(\"Chat\", response, 1, 1))\n",
    "                \n",
    "                # Adiciona a mensagem à lista de mensagens já respondidas\n",
    "                already_responded.add(cleaned_message)\n",
    "\n",
    "# Intercepta pacotes indo para o cliente e para o servidor\n",
    "ext.intercept(Direction.TO_CLIENT, all_packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This version of G-Python requires G-Earth >= 1.4.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensagem capturada: 'Kepler, beleza?\n",
      "Mensagem capturada: àÈ'Kepler, beleza?The first time I saw the new Star Wars movie, I was so excited. I was so excited to see the new Star Wars movie. I was so excited to see the new Star Wars movie. I was so excited to se\n",
      "Mensagem capturada: áÉÃ Ã'Kepler, beleza?The first time I saw the new Star Wars movie, I was so excited. I was so excited to see the new Star Wars movie. I was so excited to see the new Star Wars movie. I was so excited to\n",
      "Mensagem capturada: âÊÃ¡ÃÃÃ'Kepler, beleza?The first time I saw the new Star Wars movie, I was so excited. I was so excited to see the new Star Wars movie. I was so excited to see the new Star Wars movie. I was so excited\n",
      "Mensagem capturada: çÏÃ¢ÃÃÂ¡ÃÃÃ'Kepler, beleza?The first time I saw the new Star Wars movie, I was so excited. I was so excited to see the new Star Wars movie. I was so excited to see the new Star Wars movie. I was so excite\n",
      "Mensagem capturada: ëÓÃ§ÃÃÂ¢ÃÃÃÂ¡ÃÃÃ'Kepler, beleza?The first time I saw the new Star Wars movie, I was so excited. I was so excited to see the new Star Wars movie. I was so excited to see the new Star Wars movie. I was so ex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not send packet because G-Earth isn't connected to a client\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extension_info = {\n",
    "    \"title\": \"Extension stuff\",\n",
    "    \"description\": \"g_python test\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"author\": \"sirjonasxx\"\n",
    "}\n",
    "sys.argv = ['-p', ' 9092']\n",
    "ext = Extension(extension_info, sys.argv)\n",
    "ext.start()\n",
    "\n",
    "# Carregar o modelo e o tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Função para verificar se uma string está codificada em UTF-8\n",
    "def is_utf8(data):\n",
    "    try:\n",
    "        data.encode('utf-8')\n",
    "        return True\n",
    "    except UnicodeError:\n",
    "        return False\n",
    "\n",
    "# Variável para armazenar mensagens já respondidas\n",
    "already_responded = set()\n",
    "\n",
    "# Função de interceptação e filtragem de mensagens\n",
    "def all_packets(message):\n",
    "    packet = message.packet\n",
    "    packet_str = packet.g_string(ext)\n",
    "    \n",
    "    # Extrair a frase da mensagem removendo números e arrays e caracteres extras\n",
    "    cleaned_message = re.sub(r'[\\[\\]\\d+Æ!)]', '', packet_str).strip()\n",
    "    \n",
    "    # Verifica se a mensagem contém a palavra \"Rasci\" (case-insensitive)\n",
    "    if re.search(r'kepler', cleaned_message, re.IGNORECASE):\n",
    "        # Verifica se a mensagem está codificada em UTF-8\n",
    "        if is_utf8(cleaned_message):\n",
    "            # Verifica se a mensagem já foi respondida\n",
    "            if cleaned_message not in already_responded:\n",
    "                # Armazena a mensagem capturada\n",
    "                print(f\"Mensagem capturada: {cleaned_message}\")\n",
    "                \n",
    "                # Gerar resposta usando o modelo de linguagem\n",
    "                inputs = tokenizer.encode(cleaned_message + tokenizer.eos_token, \n",
    "                                          return_tensors=\"pt\")\n",
    "                \n",
    "                outputs = model.generate(inputs, max_length=100, \n",
    "                                         num_return_sequences=1, \n",
    "                                         attention_mask=inputs.ne(0), \n",
    "                                         pad_token_id=tokenizer.eos_token_id)\n",
    "                \n",
    "                response = tokenizer.decode(outputs[0], \n",
    "                                            skip_special_tokens=True)\n",
    "                \n",
    "                # Enviar a resposta para o servidor\n",
    "                ext.send_to_server(HPacket(\"Chat\", response, 1, 1))\n",
    "                \n",
    "                # Adiciona a mensagem à lista de mensagens já respondidas\n",
    "                already_responded.add(cleaned_message)\n",
    "                \n",
    "                # Pausa por 5 segundos\n",
    "                time.sleep(5)\n",
    "\n",
    "# Intercepta pacotes indo para o cliente e para o servidor\n",
    "ext.intercept(Direction.TO_CLIENT, all_packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext.intercept(Direction.TO_CLIENT, all_packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension_info = {\n",
    "    \"title\": \"Extension stuff\",\n",
    "    \"description\": \"g_python test\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"author\": \"sirjonasxx\"\n",
    "}\n",
    "sys.argv = ['-p', '9092']\n",
    "ext = Extension(extension_info, sys.argv)\n",
    "ext.start()\n",
    "\n",
    "# Carregar o modelo e o tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "# Função para verificar se uma string está codificada em UTF-8\n",
    "def is_utf8(data):\n",
    "    try:\n",
    "        data.encode('utf-8')\n",
    "        return True\n",
    "    except UnicodeError:\n",
    "        return False\n",
    "\n",
    "# Variável para armazenar mensagens já respondidas\n",
    "already_responded = set()\n",
    "\n",
    "# Função de interceptação e filtragem de mensagens\n",
    "def all_packets(message):\n",
    "    packet = message.packet\n",
    "    packet_str = packet.g_string(ext)\n",
    "    \n",
    "    # Extrair a frase da mensagem removendo números e arrays e caracteres extras\n",
    "    cleaned_message = re.sub(r'[\\[\\]\\d+Æ!)]', '', packet_str).strip()\n",
    "    \n",
    "    # Verifica se a mensagem contém a palavra \"Rasci\" (case-insensitive)\n",
    "    if re.search(r'kepler', cleaned_message, re.IGNORECASE):\n",
    "        # Verifica se a mensagem está codificada em UTF-8\n",
    "        if is_utf8(cleaned_message):\n",
    "            # Verifica se a mensagem já foi respondida\n",
    "            if cleaned_message not in already_responded:\n",
    "                # Armazena a mensagem capturada\n",
    "                print(f\"Mensagem capturada: {cleaned_message}\")\n",
    "                \n",
    "                # Gerar resposta usando o modelo de linguagem\n",
    "                inputs = tokenizer.encode(cleaned_message + tokenizer.eos_token, return_tensors=\"pt\")\n",
    "                outputs = model.generate(inputs, max_length=100, num_return_sequences=1)\n",
    "                response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                \n",
    "                # Enviar a resposta para o servidor\n",
    "                ext.send_to_server(HPacket(\"Chat\", response, 1, 1))\n",
    "                \n",
    "                # Adiciona a mensagem à lista de mensagens já respondidas\n",
    "                already_responded.add(cleaned_message)\n",
    "\n",
    "# Intercepta pacotes indo para o cliente e para o servidor\n",
    "ext.intercept(Direction.TO_CLIENT, all_packets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
