{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ele é um dos maiores nomes da política brasileira\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "model = GPT4All(\"Phi-3-mini-4k-instruct.Q4_0.gguf\")\n",
    "output = model.generate(\n",
    "    prompt=\"Você conhece Lula?\", \n",
    "    max_tokens=75,\n",
    ")\n",
    "\n",
    "if any(seq in output for seq in [\".\"]):\n",
    "    index = min(output.find(seq) for seq in [\".\"] if seq in output)\n",
    "    output = output[:index]\n",
    "\n",
    "# Remove canracteres indesejados do texto gerado\n",
    "output_clean = output.replace(\"\\\\n\", \"\").replace(\"\\\\t\", \"\").replace(\"===\",\"\").replace(\"<br />\", \"\")\n",
    "\n",
    "print(output_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This version of G-Python requires G-Earth >= 1.4.1\n"
     ]
    }
   ],
   "source": [
    "# Importações e configuração do modelo GPT4All\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "# Importações para a extensão g_python\n",
    "import sys\n",
    "from g_python.gextension import Extension\n",
    "from g_python.hmessage import Direction, HMessage\n",
    "from g_python.hpacket import HPacket\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Informações da extensão\n",
    "extension_info = {\n",
    "    \"title\": \"Extension stuff\",\n",
    "    \"description\": \"g_python test\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"author\": \"sirjonasxx\"\n",
    "}\n",
    "sys.argv = ['-p', '9092']\n",
    "ext = Extension(extension_info, sys.argv)\n",
    "ext.start()\n",
    "\n",
    "# Carregar o modelo GPT-4-mini-4k-instruct\n",
    "gpt4all_model = GPT4All(\"Phi-3-mini-4k-instruct.Q4_0.gguf\")\n",
    "\n",
    "# Função para verificar se uma string está codificada em UTF-8\n",
    "def is_utf8(data):\n",
    "    try:\n",
    "        data.encode('utf-8')\n",
    "        return True\n",
    "    except UnicodeError:\n",
    "        return False\n",
    "\n",
    "# Variável para armazenar mensagens já respondidas\n",
    "already_responded = set()\n",
    "\n",
    "# Função de interceptação e filtragem de mensagens\n",
    "def all_packets(message):\n",
    "    packet = message.packet\n",
    "    packet_str = packet.g_string(ext)\n",
    "    \n",
    "    # Extrair a frase da mensagem removendo números, arrays e caracteres extras\n",
    "    cleaned_message = re.sub(r'[\\[\\]\\d+Æ!)]', '', packet_str).strip()\n",
    "    \n",
    "    # Verifica se a mensagem contém a palavra \"Testkepler\" (case-insensitive)\n",
    "    if re.search(r'Testkepler', cleaned_message, re.IGNORECASE):\n",
    "        # Verifica se a mensagem está codificada em UTF-8\n",
    "        if is_utf8(cleaned_message):\n",
    "            # Verifica se a mensagem já foi respondida\n",
    "            if cleaned_message not in already_responded:\n",
    "                # Armazena a mensagem capturada\n",
    "                print(f\"Mensagem capturada: {cleaned_message}\")\n",
    "                \n",
    "                # Gerar resposta usando o modelo GPT4All com o cleaned_message como prompt\n",
    "                gpt4all_output = gpt4all_model.generate(\n",
    "                    prompt=cleaned_message, \n",
    "                    max_tokens=10,\n",
    "                )\n",
    "                \n",
    "                # Verifica e corta o texto gerado pelo modelo GPT4All no primeiro ponto final\n",
    "                if \".\" in gpt4all_output:\n",
    "                    index = gpt4all_output.find(\".\")\n",
    "                    gpt4all_output = gpt4all_output[:index]\n",
    "\n",
    "                # Remove caracteres indesejados do texto gerado\n",
    "                gpt4all_output_clean = gpt4all_output.replace(\"\\\\n\", \"\").replace(\"\\\\t\", \"\").replace(\"===\", \"\").replace(\"<br />\", \"\")\n",
    "                \n",
    "                # Enviar a resposta para o servidor\n",
    "                ext.send_to_server(HPacket(\"Chat\", gpt4all_output_clean, 1, 1))\n",
    "                \n",
    "                # Adiciona a mensagem à lista de mensagens já respondidas\n",
    "                already_responded.add(cleaned_message)\n",
    "            \n",
    "\n",
    "# Intercepta pacotes indo para o cliente e para o servidor\n",
    "ext.intercept(Direction.TO_CLIENT, all_packets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
